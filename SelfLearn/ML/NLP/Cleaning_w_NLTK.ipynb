{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "32c2db64-4192-415f-b7e8-f5b405aca02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('movie_reviews')\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "80237757-204c-4910-8d6c-86a467ec3717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movie_reviews\n",
    "data.categories()\n",
    "len(data.fileids('neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b240d2a1-5dd4-4ff7-8e3f-d645e93a3985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.words(data.fileids()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f6d0d4e7-aeb9-4a6f-a643-8caefd4353ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...], ['neg']]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = []\n",
    "for i in data.fileids():\n",
    "    arr.append([data.words(i),data.categories(i)])\n",
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef8af52e-cdb2-41e4-ba03-b70d4f56337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "906c60e9-ae19-4909-a3d5-3a482ab874ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopw = stopwords.words('english')\n",
    "# punctuation\n",
    "stopw += list(punctuation)\n",
    "stopw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e334e22e-45c0-4ef5-a1c0-c1de4a04b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in arr:\n",
    "    temp = [j for j in i[0] if j not in stopw]\n",
    "    i[0] = temp\n",
    "    i[1] = i[1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "899b690e-fee5-4c20-adab-22653688d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['plot',\n",
       "  'two',\n",
       "  'teen',\n",
       "  'couples',\n",
       "  'go',\n",
       "  'church',\n",
       "  'party',\n",
       "  'drink',\n",
       "  'drive',\n",
       "  'get',\n",
       "  'accident',\n",
       "  'one',\n",
       "  'guys',\n",
       "  'dies',\n",
       "  'girlfriend',\n",
       "  'continues',\n",
       "  'see',\n",
       "  'life',\n",
       "  'nightmares',\n",
       "  'deal',\n",
       "  'watch',\n",
       "  'movie',\n",
       "  'sorta',\n",
       "  'find',\n",
       "  'critique',\n",
       "  'mind',\n",
       "  'fuck',\n",
       "  'movie',\n",
       "  'teen',\n",
       "  'generation',\n",
       "  'touches',\n",
       "  'cool',\n",
       "  'idea',\n",
       "  'presents',\n",
       "  'bad',\n",
       "  'package',\n",
       "  'makes',\n",
       "  'review',\n",
       "  'even',\n",
       "  'harder',\n",
       "  'one',\n",
       "  'write',\n",
       "  'since',\n",
       "  'generally',\n",
       "  'applaud',\n",
       "  'films',\n",
       "  'attempt',\n",
       "  'break',\n",
       "  'mold',\n",
       "  'mess',\n",
       "  'head',\n",
       "  'lost',\n",
       "  'highway',\n",
       "  'memento',\n",
       "  'good',\n",
       "  'bad',\n",
       "  'ways',\n",
       "  'making',\n",
       "  'types',\n",
       "  'films',\n",
       "  'folks',\n",
       "  'snag',\n",
       "  'one',\n",
       "  'correctly',\n",
       "  'seem',\n",
       "  'taken',\n",
       "  'pretty',\n",
       "  'neat',\n",
       "  'concept',\n",
       "  'executed',\n",
       "  'terribly',\n",
       "  'problems',\n",
       "  'movie',\n",
       "  'well',\n",
       "  'main',\n",
       "  'problem',\n",
       "  'simply',\n",
       "  'jumbled',\n",
       "  'starts',\n",
       "  'normal',\n",
       "  'downshifts',\n",
       "  'fantasy',\n",
       "  'world',\n",
       "  'audience',\n",
       "  'member',\n",
       "  'idea',\n",
       "  'going',\n",
       "  'dreams',\n",
       "  'characters',\n",
       "  'coming',\n",
       "  'back',\n",
       "  'dead',\n",
       "  'others',\n",
       "  'look',\n",
       "  'like',\n",
       "  'dead',\n",
       "  'strange',\n",
       "  'apparitions',\n",
       "  'disappearances',\n",
       "  'looooot',\n",
       "  'chase',\n",
       "  'scenes',\n",
       "  'tons',\n",
       "  'weird',\n",
       "  'things',\n",
       "  'happen',\n",
       "  'simply',\n",
       "  'explained',\n",
       "  'personally',\n",
       "  'mind',\n",
       "  'trying',\n",
       "  'unravel',\n",
       "  'film',\n",
       "  'every',\n",
       "  'give',\n",
       "  'clue',\n",
       "  'get',\n",
       "  'kind',\n",
       "  'fed',\n",
       "  'film',\n",
       "  'biggest',\n",
       "  'problem',\n",
       "  'obviously',\n",
       "  'got',\n",
       "  'big',\n",
       "  'secret',\n",
       "  'hide',\n",
       "  'seems',\n",
       "  'want',\n",
       "  'hide',\n",
       "  'completely',\n",
       "  'final',\n",
       "  'five',\n",
       "  'minutes',\n",
       "  'make',\n",
       "  'things',\n",
       "  'entertaining',\n",
       "  'thrilling',\n",
       "  'even',\n",
       "  'engaging',\n",
       "  'meantime',\n",
       "  'really',\n",
       "  'sad',\n",
       "  'part',\n",
       "  'arrow',\n",
       "  'dig',\n",
       "  'flicks',\n",
       "  'like',\n",
       "  'actually',\n",
       "  'figured',\n",
       "  'half',\n",
       "  'way',\n",
       "  'point',\n",
       "  'strangeness',\n",
       "  'start',\n",
       "  'make',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'sense',\n",
       "  'still',\n",
       "  'make',\n",
       "  'film',\n",
       "  'entertaining',\n",
       "  'guess',\n",
       "  'bottom',\n",
       "  'line',\n",
       "  'movies',\n",
       "  'like',\n",
       "  'always',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'audience',\n",
       "  'even',\n",
       "  'given',\n",
       "  'secret',\n",
       "  'password',\n",
       "  'enter',\n",
       "  'world',\n",
       "  'understanding',\n",
       "  'mean',\n",
       "  'showing',\n",
       "  'melissa',\n",
       "  'sagemiller',\n",
       "  'running',\n",
       "  'away',\n",
       "  'visions',\n",
       "  '20',\n",
       "  'minutes',\n",
       "  'throughout',\n",
       "  'movie',\n",
       "  'plain',\n",
       "  'lazy',\n",
       "  'okay',\n",
       "  'get',\n",
       "  'people',\n",
       "  'chasing',\n",
       "  'know',\n",
       "  'really',\n",
       "  'need',\n",
       "  'see',\n",
       "  'giving',\n",
       "  'us',\n",
       "  'different',\n",
       "  'scenes',\n",
       "  'offering',\n",
       "  'insight',\n",
       "  'strangeness',\n",
       "  'going',\n",
       "  'movie',\n",
       "  'apparently',\n",
       "  'studio',\n",
       "  'took',\n",
       "  'film',\n",
       "  'away',\n",
       "  'director',\n",
       "  'chopped',\n",
       "  'shows',\n",
       "  'might',\n",
       "  'pretty',\n",
       "  'decent',\n",
       "  'teen',\n",
       "  'mind',\n",
       "  'fuck',\n",
       "  'movie',\n",
       "  'somewhere',\n",
       "  'guess',\n",
       "  'suits',\n",
       "  'decided',\n",
       "  'turning',\n",
       "  'music',\n",
       "  'video',\n",
       "  'little',\n",
       "  'edge',\n",
       "  'would',\n",
       "  'make',\n",
       "  'sense',\n",
       "  'actors',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'part',\n",
       "  'although',\n",
       "  'wes',\n",
       "  'bentley',\n",
       "  'seemed',\n",
       "  'playing',\n",
       "  'exact',\n",
       "  'character',\n",
       "  'american',\n",
       "  'beauty',\n",
       "  'new',\n",
       "  'neighborhood',\n",
       "  'biggest',\n",
       "  'kudos',\n",
       "  'go',\n",
       "  'sagemiller',\n",
       "  'holds',\n",
       "  'throughout',\n",
       "  'entire',\n",
       "  'film',\n",
       "  'actually',\n",
       "  'feeling',\n",
       "  'character',\n",
       "  'unraveling',\n",
       "  'overall',\n",
       "  'film',\n",
       "  'stick',\n",
       "  'entertain',\n",
       "  'confusing',\n",
       "  'rarely',\n",
       "  'excites',\n",
       "  'feels',\n",
       "  'pretty',\n",
       "  'redundant',\n",
       "  'runtime',\n",
       "  'despite',\n",
       "  'pretty',\n",
       "  'cool',\n",
       "  'ending',\n",
       "  'explanation',\n",
       "  'craziness',\n",
       "  'came',\n",
       "  'oh',\n",
       "  'way',\n",
       "  'horror',\n",
       "  'teen',\n",
       "  'slasher',\n",
       "  'flick',\n",
       "  'packaged',\n",
       "  'look',\n",
       "  'way',\n",
       "  'someone',\n",
       "  'apparently',\n",
       "  'assuming',\n",
       "  'genre',\n",
       "  'still',\n",
       "  'hot',\n",
       "  'kids',\n",
       "  'also',\n",
       "  'wrapped',\n",
       "  'production',\n",
       "  'two',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'sitting',\n",
       "  'shelves',\n",
       "  'ever',\n",
       "  'since',\n",
       "  'whatever',\n",
       "  'skip',\n",
       "  'joblo',\n",
       "  'coming',\n",
       "  'nightmare',\n",
       "  'elm',\n",
       "  'street',\n",
       "  '3',\n",
       "  '7',\n",
       "  '10',\n",
       "  'blair',\n",
       "  'witch',\n",
       "  '2',\n",
       "  '7',\n",
       "  '10',\n",
       "  'crow',\n",
       "  '9',\n",
       "  '10',\n",
       "  'crow',\n",
       "  'salvation',\n",
       "  '4',\n",
       "  '10',\n",
       "  'lost',\n",
       "  'highway',\n",
       "  '10',\n",
       "  '10',\n",
       "  'memento',\n",
       "  '10',\n",
       "  '10',\n",
       "  'others',\n",
       "  '9',\n",
       "  '10',\n",
       "  'stir',\n",
       "  'echoes',\n",
       "  '8',\n",
       "  '10'],\n",
       " 'neg']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4dcb78a4-9375-45f8-afda-18916f4d5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff4027b0-90bc-4473-9da5-8c2f897aec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a95c4bd7-5b60-4108-8966-f4a5f51f525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c77d35cb-b11e-4f73-9d30-93b94f1e1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()\n",
    "for i in arr:\n",
    "    for j in i[0]:\n",
    "        j = lemm.lemmatize(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46306f-b60d-4fa9-b09a-9ac0eb18dff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
